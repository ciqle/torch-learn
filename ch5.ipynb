{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from ch5_previous import generate_text_simple, GPTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    #1 unsqueeze(0) adds the batch dimension\n",
    "    print(encoded)\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6109, 3626, 6100, 345]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[6109, 3626, 6100,  345]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_token_ids(\"Every effort moves you\", tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_ids_to_text(token_ids: torch.tensor, tokenizer):\n",
    "    flat = token_ids.squeeze(0)\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256,\n",
    "    #1 We shorten the context length from 1,024 to 256 tokens.\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,       #2 It’s possible and common to set dropout to 0.\n",
    "    \"qkv_bias\": False\n",
    "}\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6109, 3626, 6100, 345]\n",
      "Output text:\n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Every effort moves you\"\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107, 588, 11311]])  #  \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1113, -0.1057, -0.3666,  ...,  0.2843, -0.8824,  0.1074],\n",
       "         [-0.6109, -0.5167, -0.7613,  ...,  0.5450, -1.0319, -0.2175],\n",
       "         [ 0.5707, -0.6459, -0.0701,  ...,  0.7419, -0.1806, -0.2217]],\n",
       "\n",
       "        [[-0.2968,  0.1949, -0.1649,  ..., -0.4867,  0.7218, -0.1714],\n",
       "         [-0.8375,  0.0612, -0.4641,  ...,  0.2327, -0.3889, -0.0770],\n",
       "         [ 0.5614,  0.6919,  0.8915,  ..., -0.9472,  1.2411, -0.2056]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "print(logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(probas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.8849e-05, 1.5172e-05, 1.1687e-05,  ..., 2.2409e-05,\n",
      "          6.9776e-06, 1.8776e-05],\n",
      "         [9.1569e-06, 1.0062e-05, 7.8786e-06,  ..., 2.9090e-05,\n",
      "          6.0103e-06, 1.3571e-05],\n",
      "         [2.9877e-05, 8.8507e-06, 1.5741e-05,  ..., 3.5456e-05,\n",
      "          1.4094e-05, 1.3526e-05]],\n",
      "\n",
      "        [[1.2561e-05, 2.0538e-05, 1.4332e-05,  ..., 1.0389e-05,\n",
      "          3.4784e-05, 1.4239e-05],\n",
      "         [7.2731e-06, 1.7864e-05, 1.0565e-05,  ..., 2.1206e-05,\n",
      "          1.1390e-05, 1.5559e-05],\n",
      "         [2.9496e-05, 3.3605e-05, 4.1029e-05,  ..., 6.5249e-06,\n",
      "          5.8203e-05, 1.3698e-05]]])\n"
     ]
    }
   ],
   "source": [
    "print(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 is batch size, 3 is the number of tokens in a batch, 50257 is embedding size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1:\"\n",
    "      f\" {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.4541e-05, 3.1061e-05, 1.1563e-05])\n",
      "Text 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3626, 6100,  345])\n",
      "tensor([ 1107,   588, 11311])\n"
     ]
    }
   ],
   "source": [
    "print(targets[0])\n",
    "print(targets[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.7940)\n"
     ]
    }
   ],
   "source": [
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"Logits shape:\", logits.shape)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "# (2, 3, 50257) -> (2 * 3, 50257) = (6, 50257)\n",
    "logits_flat = logits.flatten(0, 1)\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "targets_flat = targets.flatten()\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`logits_flat`里包含softmax函数之前的unscaled model outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1113, -0.1057, -0.3666,  0.0229, -0.6258])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_flat[0, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1113, -0.1057, -0.3666,  ...,  0.2843, -0.8824,  0.1074],\n",
      "        [-0.6109, -0.5167, -0.7613,  ...,  0.5450, -1.0319, -0.2175],\n",
      "        [ 0.5707, -0.6459, -0.0701,  ...,  0.7419, -0.1806, -0.2217],\n",
      "        [-0.2968,  0.1949, -0.1649,  ..., -0.4867,  0.7218, -0.1714],\n",
      "        [-0.8375,  0.0612, -0.4641,  ...,  0.2327, -0.3889, -0.0770],\n",
      "        [ 0.5614,  0.6919,  0.8915,  ..., -0.9472,  1.2411, -0.2056]])\n"
     ]
    }
   ],
   "source": [
    "print(logits_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`targets`里包含我们希望LLM生成的token ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3626)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_flat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 3626,  6100,   345,  1107,   588, 11311])\n"
     ]
    }
   ],
   "source": [
    "print(targets_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(48725.8203)\n"
     ]
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"the-verdict.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD\n",
      "ue' c\n"
     ]
    }
   ],
   "source": [
    "print(train_data[:5])\n",
    "print(val_data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1b3014386f0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ch5_previous import create_dataloader_v1\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"], # max_length=256\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"], # stride=256\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"], # max_length=256\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"], # stride=256\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for single batch\n",
    "\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0, 1),\n",
    "        target_batch.flatten()\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for all batches from a dataloader\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float('nan')\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    \n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device\n",
    "            )\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.98758316040039\n",
      "Validation loss: 10.98110580444336\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)   #1\n",
    "with torch.no_grad():                                        #2\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)    #3\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()  # Dropout is disabled during evaluation for stable, reproducible results.\n",
    "    with torch.no_grad():  # Disables gradient tracking, which is not required during evaluation, to reduce the computational overhead\n",
    "        train_loss = calc_loss_loader(\n",
    "            train_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_loss = calc_loss_loader(\n",
    "            val_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        model.train() # Going back into train model\n",
    "        return train_loss, val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model,\n",
    "            idx=encoded,\n",
    "            max_new_tokens=50,\n",
    "            context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))   # compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs,\n",
    "    eval_freq,\n",
    "    eval_iter,\n",
    "    start_context,\n",
    "    tokenizer\n",
    "):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # ？这是做什么的？\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Resets loss gradients from the previous batch iteration\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device\n",
    "            )\n",
    "            loss.backward()\n",
    "            optimizer.step() # Updates model weights using loss gradients/使用损失梯度更新模型权重\n",
    "\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0: # optional evaluation step\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, \"\n",
    "                      f\"Val loss {val_loss:.3f}\"\n",
    "                )\n",
    "        generate_and_print_sample(   # Prints a sample text after each epoch\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.825, Val loss 9.935\n",
      "Ep 1 (Step 000005): Train loss 8.067, Val loss 8.339\n",
      "[6109, 3626, 6100, 345]\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train loss 6.625, Val loss 7.053\n",
      "Ep 2 (Step 000015): Train loss 6.045, Val loss 6.600\n",
      "[6109, 3626, 6100, 345]\n",
      "Every effort moves you, and,, and,,,,,,, and,.                                   \n",
      "Ep 3 (Step 000020): Train loss 5.553, Val loss 6.501\n",
      "Ep 3 (Step 000025): Train loss 5.471, Val loss 6.394\n",
      "[6109, 3626, 6100, 345]\n",
      "Every effort moves you, and to the of the of the to the, and I had. Gis, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and,\n",
      "Ep 4 (Step 000030): Train loss 5.057, Val loss 6.306\n",
      "Ep 4 (Step 000035): Train loss 4.751, Val loss 6.304\n",
      "[6109, 3626, 6100, 345]\n",
      "Every effort moves you a the picture.      \"I had the of the picture--and it was--and     \"I\"I had the picture.              \n",
      "Ep 5 (Step 000040): Train loss 4.151, Val loss 6.171\n",
      "[6109, 3626, 6100, 345]\n",
      "Every effort moves you know the        \"Oh a little me--I---and, and I felt's the sketch of the                     \n",
      "Ep 6 (Step 000045): Train loss 3.756, Val loss 6.123\n",
      "Ep 6 (Step 000050): Train loss 3.205, Val loss 6.099\n",
      "[6109, 3626, 6100, 345]\n",
      "Every effort moves you know the fact, and pushed one of the to the fact with a little a little: \"Yes, and in fact, and. \"Oh, and I had been at my elbow and I had a little a little the room, and in\n",
      "Ep 7 (Step 000055): Train loss 3.135, Val loss 6.187\n",
      "Ep 7 (Step 000060): Train loss 2.393, Val loss 6.126\n",
      "[6109, 3626, 6100, 345]\n",
      "Every effort moves you know,\" was not that I felt he was to the fact with a little: \"Yes--and a little to me to have to see a smile behind his pictures--I had been his pictures--as of the picture--because he was his pictures\n",
      "Ep 8 (Step 000065): Train loss 1.936, Val loss 6.141\n",
      "Ep 8 (Step 000070): Train loss 1.607, Val loss 6.203\n",
      "[6109, 3626, 6100, 345]\n",
      "Every effort moves you?\"  \"Yes--I glanced after him, and uncertain.  \"Once, when I looked up, I felt to see a smile behind his close grayish beard--as if he had the donkey. \"There were days when I\n",
      "Ep 9 (Step 000075): Train loss 1.255, Val loss 6.235\n",
      "Ep 9 (Step 000080): Train loss 0.956, Val loss 6.264\n",
      "[6109, 3626, 6100, 345]\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. The rest of the house.\"      \"Oh, and I remember getting off a prodigious phrase about the honour being _mine_--because he's I had\n",
      "Ep 10 (Step 000085): Train loss 0.699, Val loss 6.365\n",
      "[6109, 3626, 6100, 345]\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(\n",
    "     model.parameters(),           #1\n",
    "    lr=0.0004, weight_decay=0.1\n",
    ")\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(\n",
    "        epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\"\n",
    "    )\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax2 = ax1.twiny()                   #1\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)     #2\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
