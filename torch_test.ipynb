{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(torch.nn.Module):\n",
    "    # Coding the number of inputs and outputs as variables allows us to \n",
    "    # reuse the same code for datasets with different numbers of features and classes\n",
    "\n",
    "    def __init__(self, num_inputs: int, num_outputs: int):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            torch.nn.Linear(num_inputs, 30), # The Linear layer takes the number of input and output nodes as arguments.\n",
    "            torch.nn.ReLU(), # Nonlinear activation functions are placed between the hidden layers.\n",
    "            torch.nn.Linear(30, 20), # The number of output nodes of one hidden layer has to match the number of inputs of the next layer.\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(20, num_outputs)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # logits represents the outputs of the last layer\n",
    "        logits = self.layers(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork(50, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=50, out_features=30, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=30, out_features=20, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=20, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of trainable model parameters: 2213\n"
     ]
    }
   ],
   "source": [
    "# numel stands for number of elements\n",
    "# model.parameters() returns an iterator over the model's trainable parameters\n",
    "# requires_grad indicates whether the parameter is trainable\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Total number of trainable model parameters:\", num_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0927,  0.0058,  0.1368,  ..., -0.0048, -0.0748,  0.0212],\n",
      "        [ 0.0371, -0.0859, -0.0827,  ...,  0.0809, -0.1081,  0.1148],\n",
      "        [-0.0823,  0.1336, -0.0933,  ..., -0.0914,  0.0672, -0.0741],\n",
      "        ...,\n",
      "        [ 0.0091,  0.1112, -0.0603,  ..., -0.0245,  0.0591, -0.0498],\n",
      "        [ 0.1117,  0.0394, -0.0382,  ..., -0.0958,  0.0097,  0.0675],\n",
      "        [ 0.0791, -0.0117, -0.0775,  ...,  0.0127,  0.0506,  0.0389]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 50])\n"
     ]
    }
   ],
   "source": [
    "# It's a 30 x 50 matrix\n",
    "print(model.layers[0].weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0577,  0.0047, -0.0702,  ...,  0.0222,  0.1260,  0.0865],\n",
      "        [ 0.0502,  0.0307,  0.0333,  ...,  0.0951,  0.1134, -0.0297],\n",
      "        [ 0.1077, -0.1108,  0.0122,  ...,  0.0108, -0.1049, -0.1063],\n",
      "        ...,\n",
      "        [-0.0787,  0.1259,  0.0803,  ...,  0.1218,  0.1303, -0.1351],\n",
      "        [ 0.1359,  0.0175, -0.0673,  ...,  0.0674,  0.0676,  0.1058],\n",
      "        [ 0.0790,  0.1343, -0.0293,  ...,  0.0344, -0.0971, -0.0509]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = NeuralNetwork(50, 3)\n",
    "print(model.layers[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1262,  0.1080, -0.1792]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "X = torch.rand((1, 50))\n",
    "out = model(X)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`AddmmBackward0` means the last-used function to compute a variable in the computation graph\n",
    "\n",
    "`Addmm` stands for matrix multiplication('mm') followed by addition ('Add')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1262,  0.1080, -0.1792]])\n"
     ]
    }
   ],
   "source": [
    "# use the network without training or backpropagation\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = model(X)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3113, 0.3934, 0.2952]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # dim=1 indicates the second dimension, which is the row\n",
    "    out = torch.softmax(model(X), dim=1)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "implement a custom Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor([\n",
    "    [-1.2, 3.1],\n",
    "    [-0.9, 2.9],\n",
    "    [-0.5, 2.6],\n",
    "    [2.3, -1.1],\n",
    "    [2.7, -1.5]\n",
    "])\n",
    "\n",
    "y_train = torch.tensor([0, 0, 0, 1, 1])\n",
    "\n",
    "X_test = torch.tensor([\n",
    "    [-0.8, 2.8],\n",
    "    [2.6, -1.6]\n",
    "])\n",
    "\n",
    "y_test = torch.tensor([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 2])\n",
      "torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ToyDataset(Dataset):\n",
    "    def __init__(self, X, y) -> None:\n",
    "        super().__init__()\n",
    "        self.features = X\n",
    "        self.labels = y\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        one_X = self.features[index]\n",
    "        one_y = self.labels[index]\n",
    "        return one_X, one_y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "train_ds = ToyDataset(X_train, y_train)\n",
    "test_ds = ToyDataset(X_test, y_test)\n",
    "print(len(train_ds))\n",
    "print(len(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_ds, # serves as input to the data loader\n",
    "    batch_size=2,\n",
    "    shuffle=True, # whether to shuffle the data or not\n",
    "    num_workers=0 # the number of background processes, 0 means data loading will be done in the main process and not in separate worker processes\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_ds,\n",
    "    batch_size=2,\n",
    "    shuffle=False, # it is not necessary to shuffle a test dataset\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: tensor([[ 2.3000, -1.1000],\n",
      "        [-0.9000,  2.9000]]) tensor([1, 0])\n",
      "Batch 2: tensor([[-1.2000,  3.1000],\n",
      "        [-0.5000,  2.6000]]) tensor([0, 0])\n",
      "Batch 3: tensor([[ 2.7000, -1.5000]]) tensor([1])\n"
     ]
    }
   ],
   "source": [
    "for idx, (x, y) in enumerate(train_loader):\n",
    "    print(f\"Batch {idx + 1}:\", x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A typical training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/003  | Batch 000/003  | Train Loss: 0.75\n",
      "Epoch: 001/003  | Batch 001/003  | Train Loss: 0.65\n",
      "Epoch: 001/003  | Batch 002/003  | Train Loss: 0.42\n",
      "Epoch: 002/003  | Batch 000/003  | Train Loss: 0.05\n",
      "Epoch: 002/003  | Batch 001/003  | Train Loss: 0.13\n",
      "Epoch: 002/003  | Batch 002/003  | Train Loss: 0.00\n",
      "Epoch: 003/003  | Batch 000/003  | Train Loss: 0.01\n",
      "Epoch: 003/003  | Batch 001/003  | Train Loss: 0.00\n",
      "Epoch: 003/003  | Batch 002/003  | Train Loss: 0.02\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "model = NeuralNetwork(\n",
    "    num_inputs=2, # two features\n",
    "    num_outputs=2 # two classes\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=0.5\n",
    ")\n",
    "\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    model.train() # put the model into training mode\n",
    "    for batch_idx, (features, labels) in enumerate(train_loader):\n",
    "        logits = model(features)\n",
    "        loss = F.cross_entropy(logits, labels) # will internally apply softmax \n",
    "\n",
    "        # sets the gradients from the previous round to 0\n",
    "        # to prevent unintended gradients accumulation\n",
    "        optimizer.zero_grad() \n",
    "        # computes the gradient of the loss given the model parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # the optimizer uses the gradients to update the model parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        ### LOGGING\n",
    "        print(f\"Epoch: {epoch+1:03d}/{num_epochs:03d} \"\n",
    "              f\" | Batch {batch_idx:03d}/{len(train_loader):03d} \"\n",
    "              f\" | Train Loss: {loss:.2f}\")\n",
    "\n",
    "    model.eval() # put the model into evaluating mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752\n"
     ]
    }
   ],
   "source": [
    "# Exercise A.3\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(num_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.9320, -4.2563],\n",
      "        [ 2.6045, -3.8389],\n",
      "        [ 2.1484, -3.2514],\n",
      "        [-2.1461,  2.1496],\n",
      "        [-2.5004,  2.5210]])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_train)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0.9992,     0.0008],\n",
      "        [    0.9984,     0.0016],\n",
      "        [    0.9955,     0.0045],\n",
      "        [    0.0134,     0.9866],\n",
      "        [    0.0066,     0.9934]])\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "probas = torch.softmax(outputs, dim=1)\n",
    "print(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "predictions = torch.argmax(probas, dim=1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions == y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model, dataloader):\n",
    "\n",
    "    model = model.eval()\n",
    "    correct = 00\n",
    "    total_examples = 0\n",
    "\n",
    "    for idx, (features, labels) in enumerate(dataloader):\n",
    "        # use the network without training or backpropagation\n",
    "        with torch.no_grad():\n",
    "            logits = model(features)\n",
    "        predictions = torch.argmax(logits, dim=1)\n",
    "        compare = labels == predictions\n",
    "        correct += torch.sum(compare)\n",
    "        total_examples += len(compare)\n",
    "    \n",
    "    return (correct / total_examples).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(compute_accuracy(model, train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(compute_accuracy(model, test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fetch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kimin\\AppData\\Local\\Temp\\ipykernel_10548\\1197640494.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  fetched_model.load_state_dict(torch.load(\"model.pth\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetched_model = NeuralNetwork(2, 2)\n",
    "fetched_model.load_state_dict(torch.load(\"model.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 7., 9.])\n"
     ]
    }
   ],
   "source": [
    "tensor_1 = torch.tensor([1., 2., 3.])\n",
    "tensor_2 = torch.tensor([4., 5., 6.])\n",
    "print(tensor_1 + tensor_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 7., 9.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "gpu_tensor_1 = tensor_1.to(\"cuda\")\n",
    "gpu_tensor_2 = tensor_2.to(\"cuda\")\n",
    "print(gpu_tensor_1 + gpu_tensor_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/003 | Batch 000/003 | Train/Val Loss: 0.00\n",
      "Epoch: 001/003 | Batch 001/003 | Train/Val Loss: 0.01\n",
      "Epoch: 001/003 | Batch 002/003 | Train/Val Loss: 0.01\n",
      "Epoch: 002/003 | Batch 000/003 | Train/Val Loss: 0.01\n",
      "Epoch: 002/003 | Batch 001/003 | Train/Val Loss: 0.00\n",
      "Epoch: 002/003 | Batch 002/003 | Train/Val Loss: 0.00\n",
      "Epoch: 003/003 | Batch 000/003 | Train/Val Loss: 0.00\n",
      "Epoch: 003/003 | Batch 001/003 | Train/Val Loss: 0.00\n",
      "Epoch: 003/003 | Batch 002/003 | Train/Val Loss: 0.01\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "model_for_gpu = NeuralNetwork(num_inputs=2, num_outputs=2)\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.5)\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch_idx, (features, labels) in enumerate(train_loader):\n",
    "        features, labels = features.to(\"cuda\"), labels.to(\"cuda\") # transfer data onto GPU\n",
    "        logits = model(features)\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"Epoch: {epoch+1:03d}/{num_epochs:03d}\"\n",
    "              f\" | Batch {batch_idx:03d}/{len(train_loader):03d}\"\n",
    "              f\" | Train/Val Loss: {loss:.2f}\")\n",
    "        \n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(10086)\n",
    "mtx_a_cpu = torch.rand(32768, 32768)\n",
    "mtx_b_cpu = torch.rand(32768, 32768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtx_c = mtx_a_cpu @ mtx_b_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtx_a_gpu = mtx_a_cpu.to(\"cuda\")\n",
    "mtx_b_gpu = mtx_b_cpu.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtx_c_gpu = mtx_a_gpu @ mtx_b_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2018.4880, 2041.4791, 2031.8149,  ..., 2018.2648, 2035.3295,\n",
       "         2052.8489],\n",
       "        [2026.6726, 2035.2216, 2020.0175,  ..., 2012.9485, 2037.9982,\n",
       "         2056.8469],\n",
       "        [2045.0924, 2060.9529, 2056.0767,  ..., 2046.9811, 2061.7751,\n",
       "         2085.5342],\n",
       "        ...,\n",
       "        [2060.3120, 2069.1853, 2045.5758,  ..., 2050.2156, 2064.4539,\n",
       "         2078.9946],\n",
       "        [2034.2317, 2038.7274, 2038.5509,  ..., 2036.5804, 2029.4133,\n",
       "         2063.7549],\n",
       "        [2029.4775, 2060.0444, 2042.2656,  ..., 2056.8511, 2057.7588,\n",
       "         2065.4546]], device='cuda:0')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtx_c_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8200.2666, 8198.6777, 8181.6396,  ..., 8239.8711, 8225.9951,\n",
       "         8229.5234],\n",
       "        [8213.9707, 8196.9639, 8194.6924,  ..., 8226.7373, 8201.8389,\n",
       "         8220.6729],\n",
       "        [8189.1118, 8189.0659, 8176.8589,  ..., 8219.3652, 8198.1172,\n",
       "         8233.2197],\n",
       "        ...,\n",
       "        [8212.8291, 8249.0547, 8207.3115,  ..., 8274.4609, 8256.0996,\n",
       "         8238.7441],\n",
       "        [8201.0283, 8193.9648, 8179.9829,  ..., 8217.0137, 8235.7051,\n",
       "         8193.2402],\n",
       "        [8239.1836, 8245.8057, 8239.6807,  ..., 8268.0664, 8264.3438,\n",
       "         8227.7705]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtx_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3635, 0.8312, 0.2289,  ..., 0.0577, 0.9722, 0.2364],\n",
       "        [0.2871, 0.4722, 0.9638,  ..., 0.4326, 0.9892, 0.2872],\n",
       "        [0.0661, 0.0838, 0.1178,  ..., 0.8146, 0.9830, 0.7482],\n",
       "        ...,\n",
       "        [0.8237, 0.6000, 0.8225,  ..., 0.4243, 0.5663, 0.9754],\n",
       "        [0.6306, 0.7463, 0.7954,  ..., 0.4027, 0.3638, 0.1379],\n",
       "        [0.1886, 0.0503, 0.6127,  ..., 0.4108, 0.7075, 0.6877]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtx_a_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3635, 0.8312, 0.2289,  ..., 0.0577, 0.9722, 0.2364],\n",
       "        [0.2871, 0.4722, 0.9638,  ..., 0.4326, 0.9892, 0.2872],\n",
       "        [0.0661, 0.0838, 0.1178,  ..., 0.8146, 0.9830, 0.7482],\n",
       "        ...,\n",
       "        [0.8237, 0.6000, 0.8225,  ..., 0.4243, 0.5663, 0.9754],\n",
       "        [0.6306, 0.7463, 0.7954,  ..., 0.4027, 0.3638, 0.1379],\n",
       "        [0.1886, 0.0503, 0.6127,  ..., 0.4108, 0.7075, 0.6877]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtx_a_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(10086)\n",
    "mtx_a_cpu = torch.rand(32768, 32768)\n",
    "mtx_b_cpu = torch.rand(32768, 32768)\n",
    "mtx_c_cpu = mtx_a_cpu @ mtx_b_cpu\n",
    "\n",
    "mtx_a_gpu = mtx_a_cpu.to(\"cuda\")\n",
    "mtx_b_gpu = mtx_b_cpu.to(\"cuda\")\n",
    "mtx_c_gpu = mtx_a_gpu @ mtx_b_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU result: tensor([[0.3911, 1.1798, 0.5918],\n",
      "        [0.7147, 1.5514, 0.8035],\n",
      "        [0.2992, 1.3315, 0.6223]])\n",
      "GPU result: tensor([[0.3911, 1.1798, 0.5918],\n",
      "        [0.7147, 1.5514, 0.8035],\n",
      "        [0.2992, 1.3315, 0.6223]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(10086)\n",
    "torch.cuda.manual_seed_all(10086)\n",
    "\n",
    "mtx_a_cpu = torch.rand(3, 3, dtype=torch.float32)\n",
    "mtx_b_cpu = torch.rand(3, 3, dtype=torch.float32)\n",
    "mtx_c_cpu = mtx_a_cpu @ mtx_b_cpu\n",
    "\n",
    "mtx_a_gpu = mtx_a_cpu.to(\"cuda\")\n",
    "mtx_b_gpu = mtx_b_cpu.to(\"cuda\")\n",
    "mtx_c_gpu = mtx_a_gpu @ mtx_b_gpu\n",
    "\n",
    "print(\"CPU result:\", mtx_c_cpu)\n",
    "print(\"GPU result:\", mtx_c_gpu.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
